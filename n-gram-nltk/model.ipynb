{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f6aa63e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in ./env/lib/python3.12/site-packages (3.9.1)\n",
      "Requirement already satisfied: click in ./env/lib/python3.12/site-packages (from nltk) (8.2.1)\n",
      "Requirement already satisfied: joblib in ./env/lib/python3.12/site-packages (from nltk) (1.5.1)\n",
      "Requirement already satisfied: regex>=2021.8.3 in ./env/lib/python3.12/site-packages (from nltk) (2024.11.6)\n",
      "Requirement already satisfied: tqdm in ./env/lib/python3.12/site-packages (from nltk) (4.67.1)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f1d926d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk import bigrams, trigrams, ngrams\n",
    "from nltk.corpus import reuters\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "fdfd820c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /home/aadimprajapati/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package reuters to\n",
      "[nltk_data]     /home/aadimprajapati/nltk_data...\n",
      "[nltk_data]   Package reuters is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('reuters')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d074953b",
   "metadata": {},
   "source": [
    "Reuters is a dataset in NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7ba12e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = nltk.word_tokenize(' '.join(reuters.words()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30bfd781",
   "metadata": {},
   "source": [
    "bigrams() converts word list into list of set of 2 words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "61c864fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "biwordlist = list(bigrams(tokens))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00e14dd3",
   "metadata": {},
   "source": [
    "trigrams() converts word list into list of set of 3 words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fc533e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "triplewordlist = list(trigrams(tokens))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7d2451b",
   "metadata": {},
   "source": [
    "InnerDict class creates a nested dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2fa164f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class InnerDict(defaultdict):\n",
    "    def __init__(self):\n",
    "        super().__init__(int)\n",
    "\n",
    "bimodel = defaultdict(InnerDict)\n",
    "trimodel = defaultdict(InnerDict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7a599b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for w1, w2 in biwordlist:\n",
    "    bimodel[w1][w2] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a30a9403",
   "metadata": {},
   "outputs": [],
   "source": [
    "for w1 in bimodel:\n",
    "    total_count = float(sum(bimodel[w1].values()))\n",
    "    for w2 in bimodel[w1]:\n",
    "        bimodel[w1][w2] /= total_count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3de94aed",
   "metadata": {},
   "source": [
    "Prediction for bigram dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0134520e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next Word: can\n"
     ]
    }
   ],
   "source": [
    "def predict_next_word_bigram(w1):\n",
    "    next_word = bimodel[w1]\n",
    "    if next_word:\n",
    "        predicted_word = max(next_word, key=next_word.get)\n",
    "        return predicted_word\n",
    "    else:\n",
    "        return \"No prediction available\"\n",
    "\n",
    "# Example usage\n",
    "print(\"Next Word:\", predict_next_word_bigram('you'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9576b76c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for w1, w2, w3 in triplewordlist:\n",
    "    trimodel[(w1, w2)][w3] +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e77b87b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for w1_w2 in trimodel:\n",
    "    total_count = float(sum(trimodel[w1_w2].values()))\n",
    "    for w3 in trimodel[w1_w2]:\n",
    "        trimodel[w1_w2][w3] /= total_count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cc521b0",
   "metadata": {},
   "source": [
    "Prediction for trigram dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d3c4a888",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next Word: gain\n"
     ]
    }
   ],
   "source": [
    "def predict_next_word_trigram(w1, w2):\n",
    "    next_word = trimodel[w1, w2]\n",
    "    if next_word:\n",
    "        predicted_word = max(next_word, key=next_word.get)\n",
    "        return predicted_word\n",
    "    else:\n",
    "        return \"No prediction available\"\n",
    "\n",
    "# Example usage\n",
    "print(\"Next Word:\", predict_next_word_trigram('he', 'can'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "ab2e3158",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 4\n",
    "n_grams = list(ngrams(tokens, N))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "2d6819b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ngram_model = defaultdict(lambda: defaultdict(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "572a7235",
   "metadata": {},
   "outputs": [],
   "source": [
    "for gram in n_grams:\n",
    "    context = gram[:-1] \n",
    "    target = gram[-1]\n",
    "    ngram_model[context][target] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "d61be125",
   "metadata": {},
   "outputs": [],
   "source": [
    "for context in ngram_model:\n",
    "    total_count = float(sum(ngram_model[context].values()))\n",
    "    for word in ngram_model[context]:\n",
    "        ngram_model[context][word] /= total_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "adaa5e1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next Word: collapse\n"
     ]
    }
   ],
   "source": [
    "def predict_next_word(*context_words):\n",
    "    if len(context_words) != N - 1:\n",
    "        return f\"Expected {N - 1} context words, but got {len(context_words)}\"\n",
    "    \n",
    "    context = tuple(context_words)\n",
    "    if context in ngram_model and len(ngram_model[context]) > 0:\n",
    "        next_word = max(ngram_model[context], key=ngram_model[context].get)\n",
    "        return next_word\n",
    "    else:\n",
    "        return \"No prediction available\"\n",
    "\n",
    "# Example usage\n",
    "print(\"Next Word:\", predict_next_word('the', 'stock', 'market'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5201d943",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
